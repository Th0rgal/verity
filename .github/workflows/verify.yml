name: Verify proofs

on:
  push:
    branches: [main]
    paths:
      - '.github/actions/**'
      - '.github/workflows/verify.yml'
      - 'Verity/**'
      - 'Verity.lean'
      - 'Compiler/**'
      - 'Compiler.lean'
      - 'examples/**'
      - 'test/**'
      - 'scripts/**'
      - 'docs/**'
      - 'docs-site/**'
      - 'lakefile.lean'
      - 'lake-manifest.json'
      - 'lean-toolchain'
      - 'foundry.toml'
      - 'AXIOMS.md'
      - 'README.md'
      - 'TRUST_ASSUMPTIONS.md'
  pull_request:
    paths:
      - '.github/actions/**'
      - '.github/workflows/verify.yml'
      - 'Verity/**'
      - 'Verity.lean'
      - 'Compiler/**'
      - 'Compiler.lean'
      - 'examples/**'
      - 'test/**'
      - 'scripts/**'
      - 'docs/**'
      - 'docs-site/**'
      - 'lakefile.lean'
      - 'lake-manifest.json'
      - 'lean-toolchain'
      - 'foundry.toml'
      - 'AXIOMS.md'
      - 'README.md'
      - 'TRUST_ASSUMPTIONS.md'
  workflow_dispatch:

permissions:
  contents: read

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  SOLC_VERSION: "0.8.33"
  SOLC_URL: "https://binaries.soliditylang.org/linux-amd64/solc-linux-amd64-v0.8.33+commit.64118f21"
  SOLC_SHA256: "1274e5c4621ae478090c5a1f48466fd3c5f658ed9e14b15a0b213dc806215468"

jobs:
  changes:
    runs-on: ubuntu-latest
    timeout-minutes: 5
    if: github.event_name != 'pull_request' || github.event.pull_request.draft == false
    outputs:
      code: ${{ steps.filter.outputs.code }}
    steps:
      - uses: actions/checkout@v4
      - uses: dorny/paths-filter@v3
        id: filter
        with:
          filters: |
            code:
              - '.github/actions/**'
              - '.github/workflows/verify.yml'
              - 'Verity/**'
              - 'Verity.lean'
              - 'Compiler/**'
              - 'Compiler.lean'
              - 'examples/**'
              - 'test/**'
              - 'scripts/**'
              - 'lakefile.lean'
              - 'lake-manifest.json'
              - 'lean-toolchain'
              - 'foundry.toml'

  # Python-only checks (fast, ~5s, always run)
  checks:
    runs-on: ubuntu-latest
    timeout-minutes: 5
    steps:
      - uses: actions/checkout@v4

      - name: Check property manifest references
        run: python3 scripts/check_property_manifest.py

      - name: Check property coverage
        run: python3 scripts/check_property_coverage.py

      - name: Check contract file structure
        run: python3 scripts/check_contract_structure.py

      - name: Check axiom locations in AXIOMS.md
        run: python3 scripts/check_axiom_locations.py

      - name: Check verification status artifact freshness
        run: python3 scripts/generate_verification_status.py --check

      - name: Check documentation counts
        run: python3 scripts/check_doc_counts.py

      - name: Check solc pin consistency
        run: python3 scripts/check_solc_pin.py

      - name: Check property manifest sync
        run: python3 scripts/check_property_manifest_sync.py

      - name: Check storage layout consistency
        run: python3 scripts/check_storage_layout.py

      - name: Check Lean hygiene
        run: python3 scripts/check_lean_hygiene.py

      - name: Check static gas model builtin coverage
        run: python3 scripts/check_gas_model_coverage.py

      - name: Check mapping slot abstraction boundary
        run: python3 scripts/check_mapping_slot_boundary.py

      - name: Check Yul builtin abstraction boundary
        run: python3 scripts/check_yul_builtin_boundary.py

      - name: Check EVMYulLean capability boundary
        run: python3 scripts/check_evmyullean_capability_boundary.py

      - name: Check EVMYulLean capability + unsupported-node report freshness
        run: python3 scripts/generate_evmyullean_capability_report.py --check

      - name: Check EVMYulLean adapter report freshness
        run: python3 scripts/generate_evmyullean_adapter_report.py --check

  build:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: changes
    if: needs.changes.outputs.code == 'true'
    steps:
      - uses: actions/checkout@v4

      - name: Cache elan + Lean toolchain
        id: cache-elan
        uses: actions/cache@v4
        with:
          path: ~/.elan
          key: elan-${{ hashFiles('lean-toolchain') }}

      - name: Install elan
        if: steps.cache-elan.outputs.cache-hit != 'true'
        env:
          ELAN_VERSION: "v4.1.2"
          ELAN_INIT_SHA256: "4bacca9502cb89736fe63d2685abc2947cfbf34dc87673504f1bb4c43eda9264"
        run: |
          curl -sSfL "https://raw.githubusercontent.com/leanprover/elan/${ELAN_VERSION}/elan-init.sh" -o elan-init.sh
          echo "${ELAN_INIT_SHA256}  elan-init.sh" | sha256sum -c -
          bash elan-init.sh -y --default-toolchain none
          rm elan-init.sh

      - name: Add elan to PATH
        run: echo "$HOME/.elan/bin" >> $GITHUB_PATH

      - name: Cache Lake packages
        uses: actions/cache@v4
        with:
          path: .lake
          key: lake-${{ hashFiles('lean-toolchain') }}-${{ hashFiles('lakefile.lean') }}-${{ github.sha }}
          restore-keys: |
            lake-${{ hashFiles('lean-toolchain') }}-${{ hashFiles('lakefile.lean') }}-
            lake-${{ hashFiles('lean-toolchain') }}-
          save-always: true

      - name: Build and verify all proofs
        env:
          LEAN_NUM_THREADS: 2
        run: |
          set -o pipefail
          lake build 2>&1 | tee lake-build.log

      - name: Check Lean warning non-regression
        run: python3 scripts/check_lean_warning_regression.py --log lake-build.log

      - name: Run AST pipeline regression modules
        env:
          LEAN_NUM_THREADS: 2
        run: lake build Compiler.ASTCompileTest Compiler.ASTDriverTest

      - name: Run ContractSpec feature regression module
        env:
          LEAN_NUM_THREADS: 2
        run: lake env lean Compiler/ContractSpecFeatureTest.lean

      - name: Check for sorry
        run: |
          # Count sorry across all Lean files (matching both 'sorry' and '· sorry')
          EXPECTED_SORRY=0  # All proofs complete
          ACTUAL_SORRY=$(grep -rn "sorry" Verity/ Compiler/ --include="*.lean" \
            | grep -v ":[[:space:]]*--" | grep -v "zero sorry" | grep -v "Summary" \
            | grep -v "SORRY" | grep -v "sorry_count" | grep -v "sorry placeholder" \
            | grep -v "No sorry" | grep -v "all proofs are complete" \
            | wc -l)
          echo "Found $ACTUAL_SORRY sorry statement(s) (expected $EXPECTED_SORRY)"
          if [ "$ACTUAL_SORRY" -gt "$EXPECTED_SORRY" ]; then
            echo "ERROR: New sorry introduced ($ACTUAL_SORRY found, $EXPECTED_SORRY expected)"
            grep -rn "sorry" Verity/ Compiler/ --include="*.lean" \
              | grep -v ":[[:space:]]*--" | grep -v "zero sorry" | grep -v "Summary" \
              | grep -v "SORRY" | grep -v "sorry_count" | grep -v "sorry placeholder" \
              | grep -v "No sorry" | grep -v "all proofs are complete"
            exit 1
          fi
          echo "✓ Sorry count ($ACTUAL_SORRY) within expected limit ($EXPECTED_SORRY)"

      - name: Check for axioms in proof files
        run: |
          echo "Checking for axioms in Compiler/ and Verity/..."

          # Find all axioms across both directories (excluding commented lines)
          grep -rn "^axiom " Compiler/ Verity/ --include="*.lean" | tee axioms.txt || true

          # Count axioms
          AXIOM_COUNT=$(wc -l < axioms.txt 2>/dev/null | tr -d ' ')

          echo "Found $AXIOM_COUNT axiom declaration(s)"

          if [ "$AXIOM_COUNT" -gt 0 ]; then
            echo "::warning::Found $AXIOM_COUNT axiom(s) in proof files"
            cat axioms.txt

            # Check if AXIOMS.md exists
            if [ ! -f "AXIOMS.md" ]; then
              echo "::error::AXIOMS.md not found. All axioms must be documented."
              exit 1
            fi

            # Verify each axiom is documented in AXIOMS.md
            echo "Verifying all axioms are documented..."

            # Extract axiom names from grep output
            AXIOM_NAMES=$(sed 's/.*:axiom \([a-zA-Z0-9_]*\).*/\1/' axioms.txt | sort -u)

            UNDOCUMENTED=""
            for axiom_name in $AXIOM_NAMES; do
              if ! grep -q "$axiom_name" AXIOMS.md; then
                echo "::error::Axiom '$axiom_name' not documented in AXIOMS.md"
                UNDOCUMENTED="$UNDOCUMENTED $axiom_name"
              else
                echo "✓ Axiom '$axiom_name' is documented"
              fi
            done

            if [ -n "$UNDOCUMENTED" ]; then
              echo "::error::Undocumented axioms:$UNDOCUMENTED"
              exit 1
            fi

            echo "✓ All $AXIOM_COUNT axioms are documented in AXIOMS.md"
          else
            echo "✓ No axioms found in proof files"
          fi

      - name: Build compiler
        run: lake build verity-compiler

      - name: Build difftest interpreter
        run: lake build difftest-interpreter

      - name: Generate Yul (all contracts + CryptoHash with linked libraries)
        run: |
          ./.lake/build/bin/verity-compiler \
            --link examples/external-libs/PoseidonT3.yul \
            --link examples/external-libs/PoseidonT4.yul

      - name: Generate patched Yul + patch coverage report
        run: |
          ./.lake/build/bin/verity-compiler \
            --enable-patches \
            --patch-report compiler/patch-report.tsv \
            --output compiler/yul-patched \
            --link examples/external-libs/PoseidonT3.yul \
            --link examples/external-libs/PoseidonT4.yul

      - name: Generate Yul (unified AST path)
        run: ./.lake/build/bin/verity-compiler --ast --output compiler/yul-ast

      - name: Check static gas model coverage on generated Yul (legacy + AST)
        run: |
          python3 scripts/check_gas_model_coverage.py \
            --dir compiler/yul \
            --dir compiler/yul-ast \
            --dir compiler/yul-patched

      - name: Keccak-256 self-test (validate hash implementation)
        run: python3 scripts/keccak256.py --self-test

      - name: Check selector hashing against specs
        run: python3 scripts/check_selectors.py

      - name: Setup solc
        uses: ./.github/actions/setup-solc

      - name: Compile generated Yul with solc + enforce legacy/AST diff baseline
        run: |
          python3 scripts/check_yul_compiles.py \
            --dir compiler/yul \
            --dir compiler/yul-patched \
            --dir compiler/yul-ast \
            --compare-dirs compiler/yul compiler/yul-ast \
            --allow-compare-diff-file scripts/fixtures/yul_ast_bytecode_diffs.allowlist

      - name: Check selector fixtures against solc
        run: python3 scripts/check_selector_fixtures.py

      - name: Check static gas report invariants
        run: python3 scripts/check_gas_report.py

      - name: Save static gas report snapshot
        run: lake exe gas-report > gas-report-static.tsv

      - name: Save patched static gas report snapshot
        run: lake exe gas-report --enable-patches --patch-max-iterations 2 > gas-report-static-patched.tsv

      - name: Check static gas patch delta non-regression
        run: |
          python3 scripts/check_patch_gas_delta.py \
            --baseline-report gas-report-static.tsv \
            --patched-report gas-report-static-patched.tsv \
            --min-improved-contracts 0 \
            --summary-markdown patch-gas-delta-summary.md >> "$GITHUB_STEP_SUMMARY"

      - name: Summarize patch coverage report
        run: |
          python3 - <<'PY' >> "$GITHUB_STEP_SUMMARY"
          import csv
          from collections import defaultdict
          path = "compiler/patch-report.tsv"
          rows = list(csv.DictReader(open(path), delimiter="\t"))
          totals = defaultdict(int)
          contracts = defaultdict(int)
          for row in rows:
            patch = row["patch_name"]
            if patch == "-":
              continue
            match_count = int(row["match_count"])
            totals[patch] += match_count
            contracts[patch] += 1
          print("### Patch Coverage")
          if not totals:
            print("No patch rules fired in this run.")
          else:
            print("| Patch | Total Matches | Contracts |")
            print("| :-- | --: | --: |")
            for patch, total in sorted(totals.items(), key=lambda kv: kv[1], reverse=True):
              print(f"| `{patch}` | {total} | {contracts[patch]} |")
          PY

      - name: Generate property coverage report
        run: python3 scripts/report_property_coverage.py --format=markdown >> $GITHUB_STEP_SUMMARY

      - name: Generate storage layout report
        run: python3 scripts/check_storage_layout.py --format=markdown >> $GITHUB_STEP_SUMMARY

      - name: Upload generated Yul
        uses: actions/upload-artifact@v4
        with:
          name: generated-yul
          path: compiler/yul

      - name: Upload patched Yul
        uses: actions/upload-artifact@v4
        with:
          name: generated-yul-patched
          path: compiler/yul-patched

      - name: Upload difftest interpreter
        uses: actions/upload-artifact@v4
        with:
          name: difftest-interpreter
          path: .lake/build/bin/difftest-interpreter

      - name: Upload static gas report
        uses: actions/upload-artifact@v4
        with:
          name: static-gas-report
          path: gas-report-static.tsv

      - name: Upload patched static gas report
        uses: actions/upload-artifact@v4
        with:
          name: static-gas-report-patched
          path: gas-report-static-patched.tsv

      - name: Upload patch coverage report
        uses: actions/upload-artifact@v4
        with:
          name: patch-coverage-report
          path: compiler/patch-report.tsv

  foundry-gas-calibration:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: [changes, build]
    if: needs.changes.outputs.code == 'true'
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Download static gas report
        uses: actions/download-artifact@v4
        with:
          name: static-gas-report

      - name: Setup Foundry environment
        uses: ./.github/actions/setup-foundry

      - name: Check static-vs-foundry gas calibration
        env:
          FOUNDRY_PROFILE: difftest
        run: python3 scripts/check_gas_calibration.py --static-report gas-report-static.tsv

  foundry:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: [changes, build]
    if: needs.changes.outputs.code == 'true'
    strategy:
      fail-fast: false
      matrix:
        shard_index: [0, 1, 2, 3, 4, 5, 6, 7]
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Setup Foundry environment
        uses: ./.github/actions/setup-foundry

      - name: Run Foundry tests with seed 42
        env:
          FOUNDRY_PROFILE: difftest
          DIFFTEST_RANDOM_SMALL: "100"
          DIFFTEST_RANDOM_LARGE: "10000"
          DIFFTEST_RANDOM_SEED: "42"
          DIFFTEST_SHARD_COUNT: "8"
          DIFFTEST_SHARD_INDEX: "${{ matrix.shard_index }}"
        run: |
          echo "Running tests with seed 42 (shard ${{ matrix.shard_index }}/8)"
          forge test

  # Multi-seed testing to detect flakiness and seed-dependent failures
  foundry-multi-seed:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: [changes, build]
    if: needs.changes.outputs.code == 'true'
    strategy:
      fail-fast: false  # Test all seeds even if one fails
      matrix:
        seed: [0, 1, 42, 123, 999, 12345, 67890]
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Setup Foundry environment
        uses: ./.github/actions/setup-foundry

      - name: Run tests with seed ${{ matrix.seed }}
        env:
          FOUNDRY_PROFILE: difftest
          DIFFTEST_RANDOM_SMALL: "100"
          DIFFTEST_RANDOM_LARGE: "10000"
          DIFFTEST_RANDOM_SEED: "${{ matrix.seed }}"
          DIFFTEST_SHARD_COUNT: "1"  # No sharding for multi-seed tests
          DIFFTEST_SHARD_INDEX: "0"
        run: |
          echo "::group::Testing with seed ${{ matrix.seed }}"
          echo "DIFFTEST_RANDOM_SEED=${{ matrix.seed }}"
          # Skip Random10000 tests in multi-seed to avoid out-of-gas errors
          # See issue #96 for details
          forge test --no-match-test "Random10000"
          echo "::endgroup::"

      - name: Report seed-specific failure
        if: failure()
        run: |
          echo "::error::Tests failed with seed ${{ matrix.seed }}"
          echo "::notice::Reproduce locally: FOUNDRY_PROFILE=difftest DIFFTEST_RANDOM_SEED=${{ matrix.seed }} forge test --no-match-test \"Random10000\" -vv"
